{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pprint\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import re\n",
    "import wave\n",
    "import contextlib\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Audio duration helper funcs ##########\n",
    "def get_wavs(path, result_list):\n",
    "    # Adds path to all wav files to result_list\n",
    "    pattern = re.compile(\"^\\S+.wav$\")\n",
    "    \n",
    "    for file in os.listdir(path):\n",
    "        if os.path.isdir(f\"{path}/{file}\"):\n",
    "            get_wavs(f\"{path}/{file}\", result_list)\n",
    "        elif pattern.match(file):\n",
    "            result_list.append(f\"{path}/{file}\")\n",
    "            \n",
    "def get_duration(fname):\n",
    "    try:\n",
    "        with contextlib.closing(wave.open(fname,'r')) as f:\n",
    "            frames = f.getnframes()\n",
    "            rate = f.getframerate()\n",
    "            duration = frames / float(rate)\n",
    "        return duration\n",
    "    except EOFError:\n",
    "        return 10000000\n",
    "\n",
    "def get_shorter_than_10s_wavs(path):\n",
    "    wav_paths = []\n",
    "    get_wavs(path, wav_paths)\n",
    "    if True:\n",
    "        return [path_cleaner(i) for i in wav_paths if get_duration(i) <= 10.0]\n",
    "    return [i for i in wav_paths if get_duration(i) <= 10.0]\n",
    "########## Metadata funcs ##########\n",
    "\n",
    "def path_cleaner(path_string):\n",
    "    # Removes unnessesary path parts, used for file comparison\n",
    "    return '/'.join(path_string.split('/')[-3:])\n",
    "\n",
    "def get_sent_paths(dataset_path):\n",
    "    # Get only directorys\n",
    "    dataset = [i for i in os.listdir(dataset_path) if os.path.isdir(f\"{dataset_path}/{i}\")]\n",
    "    sent_paths = []\n",
    "    for person in dataset:\n",
    "        sent_paths.append(f\"{dataset_path}/{person}/sentences.csv\")\n",
    "    return sent_paths\n",
    "\n",
    "def get_metadata(dataset_path, add_22k=True, ignore_longer_than_10s=True):\n",
    "    paths = get_sent_paths(dataset_path)    \n",
    "    metadata_list = []\n",
    "\n",
    "    for i in paths:\n",
    "        # Add speaker id to the metadata\n",
    "        speaker_id = i.split('/')[-2]\n",
    "        with open(i) as f:\n",
    "            sentences = f.readlines()\n",
    "        metadata_list.extend([f\"{speaker_id}/{row.strip()}|{speaker_id}\" for row in sentences])\n",
    "    print(\"Combined all metadata files\")\n",
    "        \n",
    "    if add_22k:\n",
    "        # Adds -22k.wav to file ends, because the resampler changes the wav file names\n",
    "        metadata_list = [f\"{row.split('.wav')[0]}-22k.wav{row.split('.wav')[1]}\" for row in metadata_list]\n",
    "        print(\"Added -22k to all soundfile paths in metadata\")\n",
    "        \n",
    "    if ignore_longer_than_10s:\n",
    "        # Filters out rows, that are longer than 10s \n",
    "        print(\"Starting to remove lines longer than 10s, this might take a while\")\n",
    "        shorter_than_10s = get_shorter_than_10s_wavs(dataset_path)\n",
    "        new_metadata_list = [row for row in metadata_list if path_cleaner(row.split(\"|\")[0]) in shorter_than_10s]\n",
    "        print(f\"Filtered out lines longer than 10s, because of this removed about {round(100-(len(new_metadata_list)/len(metadata_list))*100,2)}% of the corpus\")\n",
    "        metadata_list = new_metadata_list\n",
    "        \n",
    "    return metadata_list\n",
    "\n",
    "def generate_metadata_file(source_path, target_path, file_name):\n",
    "    # Writes the metadata file\n",
    "    metadata_list = get_metadata(source_path)\n",
    "    \n",
    "    with open(f\"{target_path}/{file_name}\", 'w') as f:\n",
    "        f.writelines(f\"{row}\\n\" for row in metadata_list)\n",
    "    print(f\"Wrote metadata file to {target_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined all metadata files\n",
      "Added 22k to all soundfile paths in metadata\n",
      "Starting to remove lines longer than 10s, this might take a while\n",
      "Filtered out lines longer than 10s, because of this removed about 12.780000000000001% of the corpus\n",
      "Wrote metadata file to /gpfs/space/home/zuppur/cotatron/datasets/metadata/\n"
     ]
    }
   ],
   "source": [
    "generate_metadata_file(\n",
    "    '/gpfs/space/home/zuppur/cotatron/data/preprocessed_v2', \n",
    "    '/gpfs/space/home/zuppur/cotatron/datasets/metadata/', \n",
    "    'estonian_metadata.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Voice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common voice helper funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_commonvoice_meta(meta_file, target_path):\n",
    "    # Reads the meta file to df\n",
    "    print(\"Reading metadata file and formating it\")\n",
    "    df = pd.read_csv(meta_file, delimiter='\\t')\n",
    "    # Replaces .mp3 with -22k.wav because we change the file type\n",
    "    df['path'] = df['path'].apply(lambda x: x.replace('.mp3', '-22k.wav'))\n",
    "    meta = [f\"{target_path}/{row['path']}|{row['sentence']}|{row['client_id']}\" for index, row in df.iterrows()]\n",
    "    \n",
    "    # Get wav paths that are shorter than 10s\n",
    "    print('Starting to remove lines longer than 10s, this might take a while')\n",
    "    shorter_than_10s = get_shorter_than_10s_wavs('/gpfs/space/home/zuppur/cotatron/data/cv-corpus-6.1-2020-12-11/et/clips_wav')\n",
    "    new_meta = [row for row in meta if row.split('|')[0] in shorter_than_10s]\n",
    "    print(f\"Filtered out lines longer than 10s, because of this removed about {round(100-(len(new_meta)/len(meta))*100,2)}% of the corpus\")\n",
    "    \n",
    "    return new_meta\n",
    "\n",
    "#meta = read_commonvoice_meta('/gpfs/space/home/zuppur/cotatron/data/cv-corpus-6.1-2020-12-11/et/validated.tsv', 'et/clips_wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing the metadata file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with preprocessed_v2 metadata\n",
      "Combined all metadata files\n",
      "Added -22k to all soundfile paths in metadata\n",
      "Starting to remove lines longer than 10s, this might take a while\n",
      "Filtered out lines longer than 10s, because of this removed about 12.78% of the corpus\n",
      "Starting to work on commonvoice metadata\n",
      "Reading metadata file and formating it\n",
      "Starting to remove lines longer than 10s, this might take a while\n",
      "Filtered out lines longer than 10s, because of this removed about 4.9% of the corpus\n"
     ]
    }
   ],
   "source": [
    "v2_source_path = '/gpfs/space/home/zuppur/cotatron/data/preprocessed_v2'\n",
    "commonvoice_source_path = '/gpfs/space/home/zuppur/cotatron/data/cv-corpus-6.1-2020-12-11/et/validated.tsv'\n",
    "commonvoice_audio_target_path = 'et/clips_wav'\n",
    "\n",
    "print(\"Starting with preprocessed_v2 metadata\")\n",
    "preprocessed_v2_meta = get_metadata(v2_source_path)\n",
    "print(\"Starting to work on commonvoice metadata\")\n",
    "commonvoice_meta = read_commonvoice_meta(commonvoice_source_path, commonvoice_audio_target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote metadata file to /gpfs/space/home/zuppur/cotatron/datasets/metadata/\n"
     ]
    }
   ],
   "source": [
    "# Adding folder names to metadata\n",
    "preprocessed_v2_meta_2 = [f\"preprocessed_v2/{i}\" for i in preprocessed_v2_meta]\n",
    "commonvoice_meta_2 = [f\"cv-corpus-6.1-2020-12-11/{i}\" for i in commonvoice_meta]\n",
    "\n",
    "# Combining the two lists\n",
    "combined_meta = preprocessed_v2_meta_2 + commonvoice_meta_2\n",
    "\n",
    "target_path = '/gpfs/space/home/zuppur/cotatron/datasets/metadata/'\n",
    "file_name = 'estonian_metadata.txt'\n",
    "\n",
    "# Writing the metadata file\n",
    "with open(f\"{target_path}/{file_name}\", 'w') as f:\n",
    "    f.writelines(f\"{row}\\n\" for row in combined_meta)\n",
    "    print(f\"Wrote metadata file to {target_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ERR-uudised-Tonu_Karjatse'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('/gpfs/space/home/zuppur/cotatron/datasets/metadata/estonian_metadata.txt', 'r') as f:\n",
    "    sentences = f.readlines()\n",
    "    \n",
    "sentences = [i.strip().split('|')[2] for i in sentences]\n",
    "speaker_isentences"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
