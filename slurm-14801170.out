Cotatron(
  (encoder): TextEncoder(
    (embedding): Embedding(105, 512)
    (cnn): Sequential(
      (0): Sequential(
        (0): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.5, inplace=False)
      )
      (1): Sequential(
        (0): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.5, inplace=False)
      )
      (2): Sequential(
        (0): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))
        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.5, inplace=False)
      )
    )
    (lstm): LSTM(512, 256, batch_first=True, bidirectional=True)
  )
  (speaker): SpeakerEncoder(
    (relu): ReLU()
    (stem): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (cnn): ModuleList(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bn): ModuleList(
      (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (gru): GRU(256, 256, batch_first=True)
  )
  (classifier): SpkClassifier(
    (mlp): Sequential(
      (0): ReLU()
      (1): Dropout(p=0.5, inplace=False)
      (2): Linear(in_features=256, out_features=256, bias=True)
      (3): ReLU()
      (4): Dropout(p=0.5, inplace=False)
      (5): Linear(in_features=256, out_features=231, bias=True)
    )
  )
  (decoder): TTSDecoder(
    (prenet): PreNet(
      (layers): ModuleList(
        (0): Linear(in_features=80, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=256, bias=True)
      )
    )
    (postnet): PostNet(
      (cnn): Sequential(
        (0): Sequential(
          (0): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))
          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Tanh()
          (3): Dropout(p=0.5, inplace=False)
        )
        (1): Sequential(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))
          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Tanh()
          (3): Dropout(p=0.5, inplace=False)
        )
        (2): Sequential(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))
          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Tanh()
          (3): Dropout(p=0.5, inplace=False)
        )
        (3): Sequential(
          (0): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))
          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Tanh()
          (3): Dropout(p=0.5, inplace=False)
        )
        (4): Sequential(
          (0): Conv1d(512, 80, kernel_size=(5,), stride=(1,), padding=(2,))
        )
      )
    )
    (attention_rnn): ZoneoutLSTMCell(
      (lstm): LSTMCell(1024, 512)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (attention_layer): Attention(
      (v): Linear(in_features=128, out_features=1, bias=False)
      (static_filter): StaticFilter(
        (conv): Conv1d(1, 8, kernel_size=(21,), stride=(1,), padding=(10,))
        (fc): Linear(in_features=8, out_features=128, bias=False)
      )
      (dynamic_filter): DynamicFilter(
        (hypernet): Sequential(
          (0): Linear(in_features=512, out_features=128, bias=True)
          (1): Tanh()
          (2): Linear(in_features=128, out_features=168, bias=True)
        )
        (fc): Linear(in_features=8, out_features=128, bias=True)
      )
      (prior_filter): PriorFilter()
    )
    (decoder_rnn): ZoneoutLSTMCell(
      (lstm): LSTMCell(1280, 512)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (mel_fc): Linear(in_features=1280, out_features=80, bias=True)
  )
  (audio2mel): Audio2Mel()
)
Traceback (most recent call last):
  File "cotatron_trainer.py", line 73, in <module>
    main(args)
  File "cotatron_trainer.py", line 52, in main
    trainer.fit(model)
  File "/gpfs/space/home/zuppur/.conda/envs/cotatron_env/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 582, in fit
    self.ddp_train(task, model)
  File "/gpfs/space/home/zuppur/.conda/envs/cotatron_env/lib/python3.8/site-packages/pytorch_lightning/trainer/distrib_data_parallel.py", line 342, in ddp_train
    self.run_pretrain_routine(model)
  File "/gpfs/space/home/zuppur/.conda/envs/cotatron_env/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 748, in run_pretrain_routine
    self.logger.log_hyperparams(ref_model.hparams)
  File "/gpfs/space/home/zuppur/.conda/envs/cotatron_env/lib/python3.8/site-packages/pytorch_lightning/loggers/base.py", line 18, in wrapped_fn
    fn(self, *args, **kwargs)
  File "/gpfs/space/home/zuppur/.conda/envs/cotatron_env/lib/python3.8/site-packages/pytorch_lightning/loggers/tensorboard.py", line 113, in log_hyperparams
    exp, ssi, sei = hparams(params, {})
  File "/gpfs/space/home/zuppur/.conda/envs/cotatron_env/lib/python3.8/site-packages/torch/utils/tensorboard/summary.py", line 156, in hparams
    raise ValueError('value should be one of int, float, str, bool, or torch.Tensor')
ValueError: value should be one of int, float, str, bool, or torch.Tensor
